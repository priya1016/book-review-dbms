{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af30249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************************#\n",
    "# Program name      : Sentiment Analysis for GoodRead Books                              #\n",
    "# Project           : Online Book Review System                                          #\n",
    "# Description       : IDMP_Project                                                       #\n",
    "# Produced by       : APOORVA GUPTA AND PRIYA GARG                                       #\n",
    "# Date              : 12/11/2021                                                         #\n",
    "#****************************************************************************************#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932157e",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9d1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e22cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a57d7",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78928a39",
   "metadata": {},
   "source": [
    "### Getting Review Data for top 200 most popular books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c13297",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.read_csv('../data/top_200_books.csv')\n",
    "reviews_df = pd.read_csv(\"../data/review_mystery_thriller_crime.csv\")\n",
    "reviews_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "books = books_df['id'].unique()\n",
    "book_titles = books_df[books_df['id'].isin(books)]\n",
    "book_titles = book_titles[['id','title']]\n",
    "\n",
    "book_titles['book_id'] = book_titles['id']\n",
    "book_titles.drop(columns=['id'],inplace=True)\n",
    "\n",
    "reviews_updated = pd.DataFrame(columns=reviews_df.columns)\n",
    "for book in books:\n",
    "    \n",
    "    temp = reviews_df[reviews_df['book_id'] == book].sort_values(by=['n_votes'], ascending=False)\n",
    "    \n",
    "    reviews_updated = pd.concat([reviews_updated, temp], ignore_index = True)\n",
    "\n",
    "reviews = reviews_updated.merge(book_titles,on=['book_id'],how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df196c11",
   "metadata": {},
   "source": [
    "#### Relevant Reviews: Reviews which have at least one upvote. Sentiment analysis is performed only for relevant reviews. This is done to avoid gibberish reviews which don't make any sense and hence, irrelevant to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bf87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews['n_votes'] >= 1]\n",
    "reviews.to_csv('../data/relevant_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d114c1",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe70d8",
   "metadata": {},
   "source": [
    "#### The rating columns contain ratings given by a user to specific book. It is a good estimator of the user's sentiment towards the book. For our analysis, we will use this variable as our target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86160dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('../data/relevant_reviews.csv')\n",
    "\n",
    "# bucket ratings for +ve, -ve and neutral reviews\n",
    "conditions = [\n",
    "    (reviews['rating'] <= 2),\n",
    "    (reviews['rating'] == 3 ),\n",
    "    (reviews['rating'] >= 4)\n",
    "    ]\n",
    "\n",
    "# values\n",
    "values = [-1,0,1]\n",
    "\n",
    "# getting target variable\n",
    "reviews['sentiment'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4dc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reviews[['book_id','review_text','sentiment']].copy()\n",
    "df['review_text'] = df['review_text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3076f0d",
   "metadata": {},
   "source": [
    "## Processing Texts for Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55084dd6",
   "metadata": {},
   "source": [
    "#### Functions required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13715dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from reviews\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    # removing all spl characters and numbers\n",
    "    return text\n",
    "\n",
    "\n",
    "# dictionary to tag Parts of Speech\n",
    "dict_pos = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "# tokenize, tag pos and remove stopwords\n",
    "def token_stop_pos_all(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    # creating tags for every word in review\n",
    "    newlist_words=[]\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist_words.append(tuple([word, dict_pos.get(tag[0])]))\n",
    "            # extracting words out of review which are not stopwords\n",
    "    return newlist_words\n",
    "\n",
    "\n",
    "# Lemmetisation\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatise(tagged_words):\n",
    "    new_lemma=\" \"\n",
    "    for word, pos in tagged_words:\n",
    "        if not pos:\n",
    "            lemma=word\n",
    "            new_lemma=new_lemma+\" \"+lemma\n",
    "        else:\n",
    "            lemma=wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            new_lemma=new_lemma+\" \"+lemma\n",
    "    return new_lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a713aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation\n",
    "df['cleaned_review'] = df['review_text'].apply(remove_punctuation)\n",
    "\n",
    "# tokenize, tag pos, remove stopwords \n",
    "df['words_tagged_pos'] = df['cleaned_review'].apply(token_stop_pos_all)\n",
    "\n",
    "# Lemmatisation\n",
    "df['lemma_review'] = df['words_tagged_pos'].apply(lemmatise)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef1c67",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ccacb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating random -1,0,1 values for base model \n",
    "np.random.seed(seed=42)\n",
    "df['pred_baseline'] = np.random.randint(-1, 2, df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688be2fa",
   "metadata": {},
   "source": [
    "## Rule Based Sentiment Analysis using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94bdc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TextBlob get subjectivity and sentiment\n",
    "def get_subjectivity(review):\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "def get_polarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "\n",
    "# Final prediction\n",
    "def prediction(score):\n",
    "    if score < 0:\n",
    "        return -1\n",
    "    elif score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9100b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Text Blob, getting subjectivity and sentiment polarity\n",
    "df['subjectivity_score'] = df['lemma_review'].apply(get_subjectivity) \n",
    "df['polarity_score'] = df['lemma_review'].apply(get_polarity) \n",
    "\n",
    "# Final Predictions\n",
    "df['pred_rule_based'] = df['polarity_score'].apply(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16362add",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f6b7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test splits\n",
    "x = df['lemma_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# split is not random, so as to preserve order\n",
    "x, x_test, y, y_test = train_test_split(x,y, test_size=0.25, random_state=42,shuffle=False)\n",
    "\n",
    "# Vectorize text reviews to numbers\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "x = vec.fit_transform(x).toarray()\n",
    "x_test = vec.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070ea6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aaa8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_NB_train = model.predict(x)\n",
    "predicted_NB_test = model.predict(x_test)\n",
    "\n",
    "df['prediction_nb'] = list(predicted_NB_train)+list(predicted_NB_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea22c6",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5298c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train = df.head(int(.75*len(df)))\n",
    "test = df.tail(int(.25*len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27e27c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train['lemma_review'].astype(str))\n",
    "test_matrix = vectorizer.transform(test['lemma_review'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "790c18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_matrix\n",
    "X_test = test_matrix\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03db78fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ab73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = lr.predict(X_test)\n",
    "\n",
    "predicted_lr_train = lr.predict(X_train)\n",
    "predicted_lr_test = lr.predict(X_test)\n",
    "\n",
    "df['prediction_lr'] = list(predicted_lr_train)+list(predicted_lr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e117231",
   "metadata": {},
   "source": [
    "### Comparing all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "774dbfab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE LINE\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.13      0.35      0.19      2658\n",
      "           0       0.18      0.34      0.24      3970\n",
      "           1       0.69      0.33      0.45     15216\n",
      "\n",
      "    accuracy                           0.33     21844\n",
      "   macro avg       0.33      0.34      0.29     21844\n",
      "weighted avg       0.53      0.33      0.38     21844\n",
      "\n",
      "RULE BASED\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.32      0.30      2658\n",
      "           0       0.17      0.08      0.11      3970\n",
      "           1       0.73      0.81      0.77     15216\n",
      "\n",
      "    accuracy                           0.62     21844\n",
      "   macro avg       0.39      0.40      0.39     21844\n",
      "weighted avg       0.57      0.62      0.59     21844\n",
      "\n",
      "NAIVE BAYES\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.37      0.51      2658\n",
      "           0       0.72      0.27      0.40      3970\n",
      "           1       0.78      0.97      0.86     15216\n",
      "\n",
      "    accuracy                           0.77     21844\n",
      "   macro avg       0.77      0.54      0.59     21844\n",
      "weighted avg       0.77      0.77      0.74     21844\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.72      0.79      2658\n",
      "           0       0.81      0.65      0.72      3970\n",
      "           1       0.89      0.96      0.93     15216\n",
      "\n",
      "    accuracy                           0.88     21844\n",
      "   macro avg       0.85      0.78      0.81     21844\n",
      "weighted avg       0.87      0.88      0.87     21844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BASE LINE\\n',classification_report(df['sentiment'], df['pred_baseline']))\n",
    "print('RULE BASED\\n',classification_report(df['sentiment'], df['pred_rule_based']))\n",
    "print('NAIVE BAYES\\n',classification_report(df['sentiment'], df['prediction_nb']))\n",
    "print('LOGISTIC REGRESSION\\n',classification_report(df['sentiment'], df['prediction_lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022d9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = df[['book_id','sentiment','pred_baseline','pred_rule_based','prediction_nb','prediction_lr']].copy()\n",
    "\n",
    "final_pred.to_csv('../data/all_predictions_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbcc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
